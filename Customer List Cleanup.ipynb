{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d9dc1a3-3f23-4977-8e4a-95f413d5ec08",
   "metadata": {},
   "source": [
    "# Cleaning Data from Customer List "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7e8a88-e089-4c5c-8c93-f05c1916da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9464f6d-4d85-4aff-842f-178d3cb5b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"customer_list_updated.csv\", \"r\") as f:\n",
    "    print(f.readlines(150))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d418dd6-d6be-4071-bbce-63b426e9b2c7",
   "metadata": {},
   "source": [
    "Used the open() function to read the file and see what I'm working with. Immediately noticed values were separated with pipes \"**|**\" instead of commas \"**,**\" .\n",
    "This is something I will have to specify as the delimiter when I import it as dataframe.\n",
    "\n",
    "Also, noticed a BOM(Byte-Order-Mark) **ï»¿** at the beginning of the code, which isn't shown in a notepad or VSC when I opened it and it's used for UTF files. This will cause an issue when importing if I dont encode it as UTF-8. \n",
    "\n",
    "For the sake of this project, since I need to cleanup the data, I will remove the BOM and replace the \"|\" with \",\" so it's simpler to import into a dataframe without needing to specify the delimiter and encoding it as a UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab96837-cbb3-4239-afee-d0f4a07c5e02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"customer_list_updated.csv\", \"r\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Manually remove BOM (first 3 indexes)\n",
    "content = content[3:] \n",
    "\n",
    "# Replace \"|\" with \",\"\n",
    "content = content.replace(\"|\", \",\")\n",
    "\n",
    "# Write the new content back to a new file\n",
    "with open(\"customer_list_ready.csv\", \"w\") as f:\n",
    "    f.write(content)\n",
    "\n",
    "# Print to verify that BOM is removed and values are separated by commas\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3c7656-69c5-4dd9-96d4-f27305bc04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with new csv file, specifying the 'cust_id' column as index\n",
    "df = pd.read_csv(\"customer_list_ready.csv\", index_col='cust_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2582a-7627-45c5-a561-a0941b894dc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Displaying the first 10 rows of df\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a68afc-6ed1-424f-80a6-438fe4da30de",
   "metadata": {},
   "source": [
    "***\n",
    "Noticed right away in the first 10 rows that the names have special characters:\n",
    "**&!** for first name initials and **.^** for last name initials\n",
    "\n",
    "I will create a code to find all names and index# to see which characters I will need to remove\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683f9736-eb95-4456-a494-50877f07cfb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop through each row in the 'name' column\n",
    "for index, name in df['name'].items():\n",
    "    valid_name = True\n",
    "\n",
    "    for char in name:\n",
    "        # Check if the character is not a letter and not a space\n",
    "        if not (char.isalpha() or char == ' '):\n",
    "            valid_name = False\n",
    "            break\n",
    "\n",
    "    # If the name is invalid, print the row's index and name\n",
    "    if not valid_name:\n",
    "        print(f\"Index {index}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a820b11e-0b7f-4257-9282-948404fcfac7",
   "metadata": {},
   "source": [
    "***\n",
    "By creating and running this function, I noticed there were many names that had characters. \n",
    "\n",
    "Most of them had the **&!** characters in the first name for initials and **.^** for last name initials. \n",
    "\n",
    "I also noticed for row 301, Miles **O[']Brien** had brackets around the apostrophe for his last name so I will specify to remove the brackets.\n",
    "\n",
    "There were also some customers that had a correct special character: hyphens **-** , so I will make sure not to remove those\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6b8ba8-f851-4319-85f8-1a997d798b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove specific unwanted characters in the 'name' column like \"&!\", \"^\", and \"[']\"\n",
    "for char in ['&!']:\n",
    "    df['name'] = df['name'].str.replace(char, '.')   # Replacing with a period\n",
    "\n",
    "for char in ['^']:\n",
    "    df['name'] = df['name'].str.replace(char, '') \n",
    "\n",
    "for char in [\"[']\"]:\n",
    "    df['name'] = df['name'].str.replace(char, \"'\")   # Removing the square brackets and reinstating an apostrophe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c84f08-f6cc-4964-9a2d-3b2d702e9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the first 10 rows to see if it changed the characters\n",
    "df.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25560e7d-c687-465b-bf1b-2d30caccce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using .info() to see how many rows are there and any other information I need\n",
    "df.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baa4ac2-1568-471a-aa9c-b29706a93039",
   "metadata": {},
   "source": [
    "***\n",
    "From the info summary, I can deduce that there are 521 entries (rows).\n",
    "The \"phone\" and \"sms-opt-out\" columns are only showing 520 non-null entries so they probably have one NaN value each\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c2b07f-8fa0-453c-8091-96644b22d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing up all null values for each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8944c427-5d8c-44db-b21e-ad8f763d2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locating which row has the NaN in the phone column\n",
    "df.loc[df['phone'].isna()] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85a32ca-e59c-4e9e-9504-16ee88e874d3",
   "metadata": {},
   "source": [
    "***\n",
    "Found out that row 301 has both NaN values I was looking for. I will go ahead and add values into the phone and sms columns for row 301. I rather do this than drop the row since it still has valuable data.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2380aa78-1dd6-423f-9fac-fc883a3c63be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[301, 'phone'] = '000-000-0000'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55ac68a-45c3-4bb9-a39f-ae87b16d3609",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[301, 'sms-opt-out'] = 'Y'  # Putting Y for opt-out since it's an invalid #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05403811-4706-4266-9c01-6b3118ef27cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[[301]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215f916d-8a3b-41a4-964c-57784d67e340",
   "metadata": {},
   "source": [
    "***\n",
    "Upon reviewing row 301 after my changes, I noticed that I created another column when I wanted to input Y for sms-opt-out. \n",
    "\n",
    "Although they're the same spelling, I think it created an additional column since the og must have a space before or after\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e66c2f7-7929-4035-9a35-47e686b7fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the og column for the name\n",
    "df.columns[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde42ef9-df50-4487-a70b-a10bed7a5096",
   "metadata": {},
   "source": [
    "***\n",
    "Confirmed that the original column for sms-opt-out had a space after so I will delete the column I created and delete the space in the original column\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749bb730-7e98-4e70-a050-3f4325487817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the column I made\n",
    "df.drop('sms-opt-out', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437eb16-b897-4fe7-8241-279f78fca068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stripping the space in all the columns, just in case\n",
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74695e38-20bc-4557-9e73-676f687a1180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming column has no space\n",
    "df.columns[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d63e9be-4754-4933-b240-f87cac455ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running my code again \n",
    "df.loc[301, 'sms-opt-out'] = 'Y'  # Putting Y for opt-out since it's an invalid #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca363e-2d9d-49f1-beaa-da36409e7966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[301]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab48443-b768-410b-a3d8-adb70e6935d0",
   "metadata": {},
   "source": [
    "***\n",
    "It worked! I will now go column by column performing a few codes to see if there are any discrepancies I need to correct\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b74517-1725-4b0f-9bae-18ed25f876f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting with the date column\n",
    "\n",
    "# Start by stripping any spaces\n",
    "df['date'] = df['date'].str.strip()\n",
    "\n",
    "# Looping through each row in the 'date column and check if the date format is correct\n",
    "for index, date in df['date'].items():\n",
    "    valid_date = True\n",
    "\n",
    "    # If date doesn't match format below, it will raise the flag false\n",
    "    if len(date) != 10 or date[4] != '-' or date[7] != '-':\n",
    "        valid_date = False\n",
    "\n",
    "    # Checking if dates are digits only (no special characters besides hyphen and no letters)\n",
    "    if not date[:4].isdigit() or not date[5:7].isdigit() or not date[8:].isdigit():\n",
    "        valid_time = False\n",
    "        \n",
    "    # If any came out invalid, it will print below\n",
    "    if not valid_date:\n",
    "        print(f\"Index {index}: {date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd5d02-457f-496f-97b3-fde85db492b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since nothing printed, all dates were inputted correctly\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9e0a60-c856-41cb-8fd7-7c6319953ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a similar code for the time column\n",
    "\n",
    "# Start by stripping any spaces\n",
    "df['time'] = df['time'].str.strip()\n",
    "\n",
    "# Looping through each row in the 'time' column and check if the time format is correct\n",
    "for index, time in df['time'].items():\n",
    "    valid_time = True\n",
    "\n",
    "    # Check if the time format is exactly 'HH:MM:SS' (length of 8, and correct position of ':')\n",
    "    if len(time) != 8 or time[2] != ':' or time[5] != ':':\n",
    "        valid_time = False\n",
    "\n",
    "    # Check if each part of the time is numeric\n",
    "    if not time[:2].isdigit() or not time[3:5].isdigit() or not time[6:].isdigit():\n",
    "        valid_time = False\n",
    "\n",
    "    # If any row is invalid, it will print below\n",
    "    if not valid_time:\n",
    "        print(f\"Index {index}: {time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ab1f0-2454-4541-b12a-b1d11e6d97fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, since nothing printed, all dates were inputted correctly:\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7c380-6c40-4201-9f54-bc10c677c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will skip the name column since it's already been cleaned and move on to the email column:\n",
    "\n",
    "# Loop through each email in the 'email' column\n",
    "for index, email in df['email'].items():\n",
    "    # Remove extra spaces (leading and trailing)\n",
    "    cleaned_email = email.strip()\n",
    "\n",
    "    # Converting email to lowercase\n",
    "    cleaned_email = cleaned_email.lower()\n",
    "\n",
    "    # Check if email doesn't contain '@' symbol AND a '.'\n",
    "    if not'@' in cleaned_email or not '.' in cleaned_email: \n",
    "         print(f\"Index {index}: {email}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d15c1-8358-4ff1-bb19-2d233fc6f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing printed so email column is clean so I will move onto the phone column:\n",
    "\n",
    "# Start by stripping any spaces\n",
    "df['phone'] = df['phone'].str.strip()\n",
    "\n",
    "# Loop through each phone number in the 'phone' column\n",
    "for index, phone in df['phone'].items():\n",
    "    valid_phone = True\n",
    "    \n",
    "    # Check if the phone number has exactly 12 characters (fitting this format: 123-456-7890)\n",
    "    if len(phone) != 12:\n",
    "        valid_phone = False\n",
    "\n",
    "    # Step 2: Check if dashes are in the correct places\n",
    "    if phone[3] != '-' or phone[7] != '-':\n",
    "        valid_phone = False\n",
    "    \n",
    "    # Step 3: Check if the characters are numbers where they should be\n",
    "    if not phone[:3].isdigit() or not phone[4:7].isdigit() or not phone[8:].isdigit():\n",
    "        valid_phone = False\n",
    "\n",
    "    # If the phone is invalid, print it\n",
    "    if not valid_phone:\n",
    "        print(f\"Index {index}: {phone}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391ef2e5-962b-45cc-b7ec-0778d9ba5f0e",
   "metadata": {},
   "source": [
    "***\n",
    "Finally, found an error in the phone column from rows 286-295! \n",
    "\n",
    "All phone #'s have a 1 before the number (specifying the country code).\n",
    "I will remove it to keep things uniform and clean\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119c9e86-0acb-4ce7-b765-fb36e3debf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each phone number in the 'phone' column\n",
    "for index, phone in df['phone'].items():\n",
    "    # Check to find the phone numbers that are 13 characters long\n",
    "    if len(phone) == 13:\n",
    "        # Removing the first character and update the phone number in the DataFrame\n",
    "        df.loc[index, 'phone'] = phone[1:]\n",
    "\n",
    "# printing rows from 286 to 295 to confirm\n",
    "df.loc[286:295]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b888684-a385-4f31-a2a9-c4aaeb58a97d",
   "metadata": {},
   "source": [
    "***\n",
    "Great! Phones have been updated and cleaned. Last, but not least, I will clean the last column\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bba136-626a-4f5a-8388-8fa34c708a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by stripping any spaces\n",
    "df['sms-opt-out'] = df['sms-opt-out'].str.strip()\n",
    "\n",
    "# Replace NaN values with 'Y' as default for customers to opt-out\n",
    "df['sms-opt-out'] = df['sms-opt-out'].fillna('Y')\n",
    "\n",
    "# Converting all entries to uppercase for uniformity\n",
    "df['sms-opt-out'] = df['sms-opt-out'].str.upper()\n",
    "\n",
    "# Checking for invalid entries\n",
    "for index, value in df['sms-opt-out'].items():\n",
    "    if value not in ['Y', 'N']:\n",
    "        print(f\"Index {index}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a78b293-b756-44c4-8762-e5eea3d75c14",
   "metadata": {},
   "source": [
    "All columns have cleaned, I will now check for any duplicates, just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7682254-b13a-4b35-b8e8-a57814751093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in the entire DataFrame\n",
    "print(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89128a32-9c21-4bbb-b528-d7f4e67a9123",
   "metadata": {},
   "source": [
    "***\n",
    "Great! All columns have cleaned!\n",
    "\n",
    "As a summary, I initally removed the BOM, and changed the delimiter from pipes **|** to commas **,**\n",
    "\n",
    "Then, I removed all the special characters in the names since that was what caught my eye first.\n",
    "\n",
    "I proceeded to check the info() summary to see how many rows I was working with and see if there were any nulls \n",
    "\n",
    "Removed the nulls in the phone and sms-opt-out column and replaced them with values, while also stripping spaces in the columns to not create new columns by accident\n",
    "\n",
    "I then, checked column by column if there were any formatting issues and found one last error in the phones column a set of numbers with 13 characters instead of 12. I stripped the numbers down to 12.\n",
    "\n",
    "Finally, the data has been cleaned and I will now export the cleaned dataframe into a file called customer_list_cleaned.csv, keeping the index true since I started with column 'cust_id\" as my index\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9f7b25-ad5b-4351-b988-a0bd85369444",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('customer_list_cleaned.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1462bf5-7bb7-4a70-bbfb-8021dece6364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
